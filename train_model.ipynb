{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1262a3",
   "metadata": {},
   "source": [
    "# Import th∆∞ vi·ªán\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53567b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tient\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio ,concatenate_datasets , load_from_disk \n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, TrainingArguments, Trainer , Wav2Vec2FeatureExtractor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, Gain\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b609f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651021df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b20443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ng√¥n ng·ªØ: {'en': 0, 'ja': 1, 'ko': 2, 'th': 3, 'vi': 4, 'zh': 5}\n"
     ]
    }
   ],
   "source": [
    "# --- Load metadata.jsonl ---\n",
    "dataset = load_dataset(\"json\", data_files=\"metadata.jsonl\", split=\"train\")\n",
    "\n",
    "# --- G√°n c·ªôt audio chu·∫©n ---\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# --- ƒê·ªãnh nghƒ©a label mapping ---\n",
    "languages = sorted(list(set(dataset[\"language\"])))\n",
    "label2id = {lang: i for i, lang in enumerate(languages)}\n",
    "id2label = {i: lang for lang, i in label2id.items()}\n",
    "\n",
    "print(\"Ng√¥n ng·ªØ:\", label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba336e",
   "metadata": {},
   "source": [
    "# Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"datasets/raw/LID\"\n",
    "\n",
    "# üîπ Danh s√°ch c√°c m√£ ng√¥n ng·ªØ c·ªßa b·∫°n\n",
    "languages = [\"en\", \"vi\", \"zh\", \"ja\", \"ko\", \"th\"]\n",
    "print(languages)\n",
    "count_file ,count_time , count_error_sr , count_error_dim = 0,0,0,0\n",
    "max , min = 5,5 \n",
    "threshold = 16000\n",
    "dict_time= {}\n",
    "for lang in languages:\n",
    "        lang_path = os.path.join(root_dir, lang)\n",
    "        # Duy·ªát qua c√°c file trong th∆∞ m·ª•c ng√¥n ng·ªØ\n",
    "        count_file = 0 \n",
    "        count_time = 0\n",
    "        for file in tqdm(os.listdir(lang_path)):\n",
    "            if file.endswith((\".wav\", \".flac\", \".mp3\")):\n",
    "                count_file += 1\n",
    "                y, sr = librosa.load(os.path.join(lang_path, file), sr=None)\n",
    "                count_time += librosa.get_duration(y=y, sr=sr)\n",
    "                if librosa.get_duration(y=y, sr=sr) > max:\n",
    "                    max = librosa.get_duration(y=y, sr=sr)\n",
    "                if librosa.get_duration(y=y, sr=sr) < min:\n",
    "                    min = librosa.get_duration(y=y, sr=sr)\n",
    "                if sr != threshold:\n",
    "                    count_error_sr += 1\n",
    "                    print(f\"Sampling rate kh√¥ng ph√π h·ª£p: {sr} Hz {file}\")\n",
    "                if y.ndim > 1:\n",
    "                    count_error_dim += 1\n",
    "                    print(f\"S·ªë k√™nh kh√¥ng ph√π h·ª£p: {y.ndim}  {file}\")\n",
    "        print(f\"S·ªë l∆∞·ª£ng file √¢m thanh trong {lang}: {count_file}\")\n",
    "        print(f\"T·ªïng th·ªùi gian √¢m thanh trong {lang}: {count_time} gi√¢y\")\n",
    "        dict_time[lang] = count_time\n",
    "        print(f\"Th·ªùi gian max: {max} gi√¢y\")\n",
    "        print(f\"Th·ªùi gian min: {min} gi√¢y\")\n",
    "        print(f\"S·ªë l∆∞·ª£ng file l·ªói sampling rate: {count_error_sr}\")\n",
    "        print(f\"S·ªë l∆∞·ª£ng file l·ªói s·ªë k√™nh: {count_error_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886252d1",
   "metadata": {},
   "source": [
    "# Preprocessing Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509dbb7d",
   "metadata": {},
   "source": [
    "1. M·ªói audio c√≥ c√πng sampling rate (th∆∞·ªùng 16kHz).\n",
    "\n",
    "2. ƒê·ªô d√†i audio kh√¥ng qu√° d√†i (gi·∫£m t·∫£i cho GPU).\n",
    "\n",
    "3. T√≠n hi·ªáu ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ bi√™n ƒë·ªô (volume, ƒë·ªô ·ªìn, kho·∫£ng l·∫∑ng).\n",
    "\n",
    "4. ƒê·∫£m b·∫£o m·ªói m·∫´u c√≥ label h·ª£p l·ªá.\n",
    "\n",
    "5. TƒÉng c∆∞·ªùng d·ªØ li·ªáu g·ªìm noise, speed , gain cho t·∫≠p train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52646f43",
   "metadata": {},
   "source": [
    "## Split data and Denoise 30% of Folder Train and Augment the remaining 10% of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055bce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéß en: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15860/15860 [37:57<00:00,  6.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è en: train=140526.9s (denoise=42158.1s), val=17565.9s, test=17565.9s | augment th√™m 2.73h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéß ja: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22307/22307 [56:52<00:00,  6.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è ja: train=162000.9s (denoise=48600.3s), val=20250.1s, test=20250.1s | augment th√™m 3.24h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéß ko: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30088/30088 [1:20:21<00:00,  6.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è ko: train=219738.2s (denoise=65921.4s), val=27467.3s, test=27467.3s | augment th√™m 4.31h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéß th: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25681/25681 [1:06:10<00:00,  6.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è th: train=175109.0s (denoise=52532.7s), val=21888.6s, test=21888.6s | augment th√™m 3.25h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéß vi: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27295/27295 [1:13:43<00:00,  6.17it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è vi: train=184615.9s (denoise=55384.8s), val=23077.0s, test=23077.0s | augment th√™m 3.65h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéß zh: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16293/16293 [45:13<00:00,  6.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è zh: train=126191.2s (denoise=37857.4s), val=15773.9s, test=15773.9s | augment th√™m 2.49h\n",
      "‚úÖ Ho√†n t·∫•t chia v√† x·ª≠ l√Ω d·ªØ li·ªáu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_data_with_denoise(\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1,\n",
    "    denoise_ratio_in_train=0.3,\n",
    "    augment_ratio_in_clean=0.1,\n",
    "):\n",
    "    root_dir = \"datasets/raw/LID\"\n",
    "    os.makedirs(\"datasets/train\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/val\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/test\", exist_ok=True)\n",
    "\n",
    "    # Output metadata\n",
    "    output_json_train = \"datasets/train/metadata_train.jsonl\"\n",
    "    output_json_val = \"datasets/val/metadata_val.jsonl\"\n",
    "    output_json_test = \"datasets/test/metadata_test.jsonl\"\n",
    "\n",
    "    # X√≥a file c≈© n·∫øu c√≥\n",
    "    for file in [output_json_train, output_json_val, output_json_test]:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "\n",
    "    # T·ªïng th·ªùi l∆∞·ª£ng m·ªói ng√¥n ng·ªØ\n",
    "    total_durations = {\n",
    "        \"en\": 175658.64012500033,\n",
    "        \"ja\": 202501.0694375005,\n",
    "        \"ko\": 274672.68950000097,\n",
    "        \"th\": 218886.2407500015,\n",
    "        \"vi\": 230769.86056249903,\n",
    "        \"zh\": 157739.02868750054,\n",
    "    }\n",
    "\n",
    "    # Ng∆∞·ª°ng chia theo t·ªâ l·ªá\n",
    "    dict_train = {lang: total_durations[lang] * train_ratio for lang in total_durations}\n",
    "    dict_val = {lang: total_durations[lang] * val_ratio for lang in total_durations}\n",
    "    dict_test = {lang: total_durations[lang] * test_ratio for lang in total_durations}\n",
    "    dict_denoise = {\n",
    "        lang: dict_train[lang] * denoise_ratio_in_train for lang in total_durations\n",
    "    }\n",
    "\n",
    "    # augment pipeline\n",
    "    augmentations = {\n",
    "        \"noise\": Compose([\n",
    "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1.0)\n",
    "    ]),\n",
    "        \"speed\": Compose([\n",
    "            TimeStretch(min_rate=0.9, max_rate=1.1, p=1.0)\n",
    "    ]),\n",
    "        \"gain\": Compose([\n",
    "            Gain(min_gain_db=-3.0, max_gain_db=3.0, p=1.0)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "    # Duy·ªát qua t·ª´ng ng√¥n ng·ªØ\n",
    "    for lang in total_durations.keys():\n",
    "        lang_path = os.path.join(root_dir, lang)\n",
    "        if not os.path.isdir(lang_path):\n",
    "            print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {lang_path}\")\n",
    "            continue\n",
    "\n",
    "        files = [\n",
    "            f for f in os.listdir(lang_path) if f.endswith((\".wav\", \".flac\", \".mp3\"))\n",
    "        ]\n",
    "        random.shuffle(files)\n",
    "\n",
    "        count_time = 0\n",
    "        denoise_time = 0\n",
    "        augment_time = 0\n",
    "\n",
    "        for file in tqdm(files, desc=f\"üéß {lang}\"):\n",
    "            audio_path = os.path.join(lang_path, file)\n",
    "\n",
    "            try:\n",
    "                duration = librosa.get_duration(path=audio_path)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è L·ªói khi ƒë·ªçc {audio_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            count_time += duration\n",
    "\n",
    "            # Train split\n",
    "            if count_time <= dict_train[lang]:\n",
    "                output_file = output_json_train\n",
    "                file_type = \"clean\"\n",
    "                augment_type = \"none\"\n",
    "\n",
    "                # ‚úÖ Denoise (30%)\n",
    "                if denoise_time < dict_denoise[lang]:\n",
    "                    try:\n",
    "                        y, sr = librosa.load(audio_path, sr=None)\n",
    "                        reduced = nr.reduce_noise(y=y, sr=sr)\n",
    "                        denoise_dir = f\"datasets/train/denoise/{lang}\"\n",
    "                        os.makedirs(denoise_dir, exist_ok=True)\n",
    "                        denoise_path = os.path.join(denoise_dir, f\"denoise_{file}\")\n",
    "                        sf.write(denoise_path, reduced, sr)\n",
    "                        audio_path = denoise_path\n",
    "                        file_type = \"denoise\"\n",
    "                        denoise_time += duration\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå L·ªói gi·∫£m nhi·ªÖu {audio_path}: {e}\")\n",
    "\n",
    "                # ‚úÖ Augment 10% trong ph·∫ßn clean (ch·ªâ khi kh√¥ng denoise)\n",
    "                elif random.random() < augment_ratio_in_clean:\n",
    "                    try:\n",
    "                        y, sr = librosa.load(audio_path, sr=None)\n",
    "                        aug_choice = random.choice(list(augmentations.keys()))\n",
    "                        y_aug = augmentations[aug_choice](samples=y, sample_rate=sr)\n",
    "\n",
    "                        aug_dir = f\"datasets/train/augment/{lang}\"\n",
    "                        os.makedirs(aug_dir, exist_ok=True)\n",
    "                        aug_path = os.path.join(aug_dir, f\"aug_{file}\")\n",
    "                        sf.write(aug_path, y_aug, sr)\n",
    "\n",
    "                        # Ghi metadata augment ri√™ng\n",
    "                        json_line_aug = {\n",
    "                            \"audio\": aug_path.replace(\"\\\\\", \"/\"),\n",
    "                            \"language\": lang,\n",
    "                            \"duration\": duration,\n",
    "                            \"type\": \"clean\",\n",
    "                            \"augment\": aug_choice,\n",
    "                        }\n",
    "                        with open(output_json_train, \"a\", encoding=\"utf-8\") as f:\n",
    "                            f.write(json.dumps(json_line_aug, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                        augment_time += duration\n",
    "                        augment_type = aug_choice\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå L·ªói augment {audio_path}: {e}\")\n",
    "\n",
    "            # Validation split\n",
    "            elif count_time <= dict_train[lang] + dict_val[lang]:\n",
    "                output_file = output_json_val\n",
    "                file_type = \"clean\"\n",
    "                augment_type = \"none\"\n",
    "\n",
    "            # Test split\n",
    "            else:\n",
    "                output_file = output_json_test\n",
    "                file_type = \"clean\"\n",
    "                augment_type = \"none\"\n",
    "\n",
    "            # ‚úÖ Ghi metadata ch√≠nh (d√π c√≥ augment hay kh√¥ng)\n",
    "            json_line = {\n",
    "                \"audio\": audio_path.replace(\"\\\\\", \"/\"),\n",
    "                \"language\": lang,\n",
    "                \"duration\": duration,\n",
    "                \"type\": file_type,\n",
    "                \"augment\": augment_type,\n",
    "            }\n",
    "\n",
    "            with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        print(\n",
    "            f\"üó£Ô∏è {lang}: train={dict_train[lang]:.1f}s (denoise={dict_denoise[lang]:.1f}s), \"\n",
    "            f\"val={dict_val[lang]:.1f}s, test={dict_test[lang]:.1f}s | augment th√™m {augment_time/3600:.2f}h\"\n",
    "        )\n",
    "\n",
    "    print(\"‚úÖ Ho√†n t·∫•t chia v√† x·ª≠ l√Ω d·ªØ li·ªáu.\")\n",
    "\n",
    "\n",
    "# ---- G·ªçi h√†m ----\n",
    "if __name__ == \"__main__\":\n",
    "    split_data_with_denoise()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c044ba",
   "metadata": {},
   "source": [
    "## Normalize Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febe0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_audio(audio_path, target_sr=16000):\n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, sr=target_sr , mono=True)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {audio_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    return librosa.util.normalize(audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd8323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ T·ªïng s·ªë file c·∫ßn chu·∫©n h√≥a: 117670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 117670/117670 [7:08:56<00:00,  4.57it/s]  \n"
     ]
    }
   ],
   "source": [
    "def normalize_from_metadata(metadata_path, save_inplace=True):\n",
    "    # ƒê·ªçc to√†n b·ªô metadata\n",
    "    with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [json.loads(line.strip()) for line in f]\n",
    "    print(f\"üìÑ T·ªïng s·ªë file c·∫ßn chu·∫©n h√≥a: {len(lines)}\")\n",
    "    \n",
    "    for item in tqdm(lines, desc = \"Normalizing\"):\n",
    "        audio_path = item[\"audio\"]\n",
    "\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file: {audio_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ƒê·ªçc v√† chu·∫©n h√≥a\n",
    "            y, sr = librosa.load(audio_path, sr=None)\n",
    "            y_norm = normalize_audio(y)\n",
    "\n",
    "            if save_inplace:\n",
    "                # Ghi ƒë√® l·∫°i file c≈©\n",
    "                sf.write(audio_path, y_norm, sr)\n",
    "            else:\n",
    "                # L∆∞u ra th∆∞ m·ª•c normalized/\n",
    "                norm_dir = os.path.join(os.path.dirname(audio_path), \"normalized\")\n",
    "                os.makedirs(norm_dir, exist_ok=True)\n",
    "                norm_path = os.path.join(norm_dir, os.path.basename(audio_path))\n",
    "                sf.write(norm_path, y_norm, sr)\n",
    "                # C·∫≠p nh·∫≠t metadata n·∫øu c·∫ßn\n",
    "                item[\"audio\"] = norm_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói x·ª≠ l√Ω {audio_path}: {e}\")\n",
    "        \n",
    "normalize_from_metadata(\"datasets/train/metadata_train.jsonl\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70582e7",
   "metadata": {},
   "source": [
    "# Audio Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9afa9",
   "metadata": {},
   "source": [
    "* File jsonl sau b∆∞·ªõc ti·ªÅn x·ª≠ l√≠ ·ªü tr∆∞·ªõc s·∫Ω c√≥ d·∫°ng nh∆∞ b√™n d∆∞·ªõi:\n",
    "\n",
    "```json\n",
    "{\"audio\": \"datasets/train/denoise/en/denoise_28Y6RJik15g__U__S102---0994.460-0999.480.wav\", \"language\": \"en\", \"duration\": 5.02, \"type\": \"denoise\", \"augment\": \"none\"}\n",
    "{\"audio\": \"datasets/train/denoise/en/denoise_HYtn-ogxziE__U__S121---1248.270-1265.120.wav\", \"language\": \"en\", \"duration\": 16.85, \"type\": \"denoise\", \"augment\": \"none\"}\n",
    "```\n",
    "\n",
    "* Ta s·∫Ω √°nh x·∫° sang file ch·ª©a vector v√† nh√£n c·ªßa audio, file m·ªõi s·∫Ω l√† float32\n",
    "\n",
    "* Ta s·∫Ω g·ªôp t·∫•t c√°c ng√¥n ng·ªØ l·∫°i v·ªõi nhau v√† tr·ªôn l·∫´n ƒë·ªÉ ch√∫ng h·ªçc ƒë∆∞·ª£c ph√¢n bi·ªát ngay t·ª´ ƒë·∫ßu v√† t·∫≠p val c≈©ng th·∫ø ƒë·ªÉ ƒë√°nh gi√° trong qu√° tr√¨nh train \n",
    "\n",
    "* V√† s·∫Ω n√©n ch√∫ng l·∫°i th√†nh c√°c .arrow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571659ef",
   "metadata": {},
   "source": [
    "## Kh·ªüi t·∫°o ƒë∆∞·ªùng d·∫´n v√† h√†m preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95eda734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gi·∫£ s·ª≠ b·∫°n ƒë√£ ch·∫°y pip install soundfile v√† c√°c th∆∞ vi·ªán kh√°c\n",
    "# L∆ØU √ù: V√å B·∫†N ƒêANG CH·∫†Y TR√äN LOCAL, H√ÉY C√ÄI ƒê·∫∂T C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT.\n",
    "\n",
    "# ======================================================\n",
    "# 1Ô∏è‚É£ C·∫§U H√åNH LOCAL\n",
    "# ======================================================\n",
    "LANGUAGES = [\"vi\", \"en\", \"ja\", \"ko\", \"zh\", \"th\"]\n",
    "MODEL_NAME = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "\n",
    "# C·∫•u h√¨nh Local c·ªßa b·∫°n\n",
    "LOCAL_BASE_DIR = \"datasets\" \n",
    "LOCAL_CACHE_DIR = f\"{LOCAL_BASE_DIR}/cache/wav2vec2\" \n",
    "\n",
    "\n",
    "JSONL_TEST_LOCAL = f\"{LOCAL_BASE_DIR}/test/metadata_test.jsonl\"\n",
    "SAVE_MAPPED_DATA_DIR = f\"{LOCAL_BASE_DIR}/cache\"\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2Ô∏è‚É£ H√ÄM TI·ªÄN X·ª¨ L√ù (S·ª¨ D·ª§NG SOUNDFILE)\n",
    "# ======================================================\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(batch):\n",
    "    \"\"\"T·∫£i audio b·∫±ng soundfile v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng.\"\"\"\n",
    "    \n",
    "    audio_path = batch[\"audio\"]\n",
    "    \n",
    "    # üí° LOGIC ƒêI·ªÄU CH·ªàNH ƒê∆Ø·ªúNG D·∫™N LOCAL:\n",
    "    # N·∫øu file audio trong JSONL ch·ªâ ch·ª©a ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi (v√≠ d·ª•: \"audio/vi/001.wav\")\n",
    "    # Ch√∫ng ta ph·∫£i n·ªëi n√≥ v·ªõi th∆∞ m·ª•c datasets g·ªëc.\n",
    "    # if not os.path.isabs(audio_path):\n",
    "    #     # N·ªëi LOCAL_BASE_DIR (datasets) v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi trong JSONL\n",
    "    #     # K·∫øt qu·∫£: datasets/audio/vi/001.wav (ƒê√∫ng v·ªõi c·∫•u tr√∫c local)\n",
    "    #     audio_path = os.path.join(LOCAL_BASE_DIR, audio_path) \n",
    "\n",
    "    if not os.path.exists(audio_path):\n",
    "        # ƒê√¢y l√† l·ªói ph·ªï bi·∫øn nh·∫•t, c·∫ßn ki·ªÉm tra k·ªπ c·∫•u tr√∫c th∆∞ m·ª•c local\n",
    "        raise FileNotFoundError(f\"‚ùå Kh√¥ng t√¨m th·∫•y file √¢m thanh: {audio_path}. Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n JSONL.\")\n",
    "\n",
    "    # Load audio b·∫±ng soundfile (·ªîn ƒë·ªãnh h∆°n torchaudio tr√™n Windows)\n",
    "    # data: numpy array, sampling_rate: int\n",
    "    data, sampling_rate = soundfile.read(audio_path)\n",
    "    \n",
    "    # X·ª≠ l√Ω √¢m thanh Stereo (2D array) -> Mono (1D array)\n",
    "    if data.ndim > 1:\n",
    "        speech_array = data.mean(axis=1) # L·∫•y trung b√¨nh hai k√™nh\n",
    "    else:\n",
    "        speech_array = data # Gi·ªØ nguy√™n mono\n",
    "\n",
    "    # X·ª≠ l√Ω d·ªØ li·ªáu cho Wav2Vec2 (Input l√† numpy array)\n",
    "    batch[\"input_values\"] = feature_extractor(\n",
    "        speech_array,\n",
    "        sampling_rate=sampling_rate,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_values[0]\n",
    "\n",
    "    batch[\"label\"] = LANGUAGES.index(batch[\"language\"])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c4aba",
   "metadata": {},
   "source": [
    "## Map danh s√°ch t·∫≠p test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "üåç B·∫ÆT ƒê·∫¶U T·∫†O T·∫¨P TEST TO√ÄN C·∫¶U (GLOBAL_test)\n",
      "=======================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6fdc8fc12d4eddaf6652612d5dfea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang tr·ªôn (shuffle) 13918 m·∫´u t·ªïng...\n",
      "B·∫Øt ƒë·∫ßu map ds_val (13918 m·∫´u)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2af2d26cf24020adcc8cd820d4fe4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13918 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map ds_val (13918 m·∫´u) th√†nh c√¥ng ...\n",
      "ƒêang l∆∞u t·∫≠p GLOBAL_val v√†o: datasets/cache\\GLOBAL_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78dfb7e7c674773a854e5f36b039c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/17 shards):   0%|          | 0/13918 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ TH√ÄNH C√îNG! ƒê√£ l∆∞u T·∫≠p Validation To√†n c·∫ßu t·∫°i:\n",
      "datasets/cache\\GLOBAL_test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "\n",
    "        \n",
    "    ds_test = load_dataset(\"json\", data_files=JSONL_TEST_LOCAL, split=\"train\")\n",
    "    # Tr·ªôn (Shuffle)\n",
    "    print(f\"ƒêang tr·ªôn (shuffle) {len(ds_test)} m·∫´u t·ªïng...\")\n",
    "    # (B√¢y gi·ªù n√≥ s·∫Ω d√πng CACHE_DIR v√† kh√¥ng b·ªã l·ªói)\n",
    "    ds_test = ds_test.shuffle(seed=42)\n",
    "    print(f\"B·∫Øt ƒë·∫ßu map ds_val ({len(ds_test)} m·∫´u)...\")\n",
    "    ds_test = ds_test.map(preprocess, batched=False)\n",
    "    \n",
    "    print(f\"Map ds_val ({len(ds_test)} m·∫´u) th√†nh c√¥ng ...\")\n",
    "    \n",
    "\n",
    "    # 4. L∆∞u ra Disk (v√†o /kaggle/working/) - Ph·∫ßn n√†y ƒë√£ ƒê√öNG\n",
    "    os.makedirs(SAVE_MAPPED_DATA_DIR, exist_ok=True)\n",
    "    test_global_save_path = os.path.join(SAVE_MAPPED_DATA_DIR, \"GLOBAL_test\")\n",
    "    \n",
    "    print(f\"ƒêang l∆∞u t·∫≠p GLOBAL_val v√†o: {test_global_save_path}\")\n",
    "    ds_test.save_to_disk(test_global_save_path)\n",
    "    \n",
    "    print(f\"\\nüéâ TH√ÄNH C√îNG! ƒê√£ l∆∞u T·∫≠p Validation To√†n c·∫ßu t·∫°i:\")\n",
    "    print(f\"{test_global_save_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI TRONG QU√Å TR√åNH T·∫†O GLOBAL_test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271e290",
   "metadata": {},
   "source": [
    "## Map danh s√°ch t·∫≠p train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"datasets\"\n",
    "LANGUAGES = [\"vi\", \"en\", \"ja\", \"ko\", \"zh\", \"th\"]\n",
    "# 1. T·∫°o m·ªôt danh s√°ch r·ªóng\n",
    "all_train_datasets = []\n",
    "print(\"B·∫Øt ƒë·∫ßu t·∫£i t·ª´ng th∆∞ m·ª•c .arrow ri√™ng l·∫ª...\")\n",
    "\n",
    "try:\n",
    "    # 2. V√≤ng l·∫∑p v√† T·∫£i t·ª´ng th∆∞ m·ª•c\n",
    "    for lang in LANGUAGES:\n",
    "        # ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c .arrow c·ªßa ng√¥n ng·ªØ (v√≠ d·ª•: /.../vi_train/vi_train)\n",
    "        lang_train_path_nested = os.path.join(DATA_PATH, f\"{lang}_train\", f\"{lang}_train\")\n",
    "        print(f\"ƒêang t·∫£i: {lang_train_path_nested}\")\n",
    "        \n",
    "        ds_lang_train = load_from_disk(lang_train_path_nested)\n",
    "        ds_lang_train = ds_lang_train.map(lambda x: x)\n",
    "        # 3. Th√™m v√†o danh s√°ch\n",
    "        all_train_datasets.append(ds_lang_train)\n",
    "        print(f\"‚úÖ ƒê√£ t·∫£i v√† cache l·∫°i {len(ds_lang_train)} m·∫´u cho '{lang}'.\")\n",
    "\n",
    "    # 4. G·ªôp (Concatenate)\n",
    "    print(\"\\nƒêang g·ªôp (concatenate) t·∫•t c·∫£ 6 dataset l·∫°i...\")\n",
    "    ds_train_global = concatenate_datasets(all_train_datasets)\n",
    "    \n",
    "    print(\"\\nüéâ TH√ÄNH C√îNG!\")\n",
    "    print(f\"Dataset to√†n c·∫ßu ƒë√£ ƒë∆∞·ª£c load v√† g·ªôp, t·ªïng c·ªông c√≥ {len(ds_train_global)} m·∫´u.\")\n",
    "    \n",
    "    # (B√¢y gi·ªù b·∫°n c√≥ th·ªÉ d√πng 'ds_train_global' ƒë·ªÉ shuffle, save_to_disk, ho·∫∑c train)\n",
    "    # V√≠ d·ª•:\n",
    "    print(\"ƒêang tr·ªôn (shuffle)...\")\n",
    "    ds_train_global = ds_train_global.shuffle(seed=42)\n",
    "    print(\"ƒêang l∆∞u ra disk...\")\n",
    "    ds_train_global.save_to_disk(r\"D:\\HuggingFace_Cache\\cache\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI KHI ƒêANG T·∫¢I: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ac63f",
   "metadata": {},
   "source": [
    "## Map danh s√°ch t·∫≠p val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8aab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"datasets\"\n",
    "LANGUAGES = [\"vi\", \"en\", \"ja\", \"ko\", \"zh\", \"th\"]\n",
    "# 1. T·∫°o m·ªôt danh s√°ch r·ªóng\n",
    "all_val_datasets = []\n",
    "print(\"B·∫Øt ƒë·∫ßu t·∫£i t·ª´ng th∆∞ m·ª•c .arrow ri√™ng l·∫ª...\")\n",
    "\n",
    "try:\n",
    "    # 2. V√≤ng l·∫∑p v√† T·∫£i t·ª´ng th∆∞ m·ª•c\n",
    "    for lang in LANGUAGES:\n",
    "        # ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c .arrow c·ªßa ng√¥n ng·ªØ (v√≠ d·ª•: /.../vi_train/vi_train)\n",
    "        lang_val_path_nested = os.path.join(DATA_PATH, f\"{lang}_val\", f\"{lang}_val\")\n",
    "        print(f\"ƒêang t·∫£i: {lang_val_path_nested}\")\n",
    "        \n",
    "        ds_lang_val = load_from_disk(lang_val_path_nested)\n",
    "        ds_lang_val = ds_lang_val.map(lambda x: x)\n",
    "        # 3. Th√™m v√†o danh s√°ch\n",
    "        all_val_datasets.append(ds_lang_val)\n",
    "        print(f\"‚úÖ ƒê√£ t·∫£i v√† cache l·∫°i {len(ds_lang_val)} m·∫´u cho '{lang}'.\")\n",
    "\n",
    "    # 4. G·ªôp (Concatenate)\n",
    "    print(\"\\nƒêang g·ªôp (concatenate) t·∫•t c·∫£ 6 dataset l·∫°i...\")\n",
    "    ds_val_global = concatenate_datasets(all_val_datasets)\n",
    "    \n",
    "    print(\"\\nüéâ TH√ÄNH C√îNG!\")\n",
    "    print(f\"Dataset to√†n c·∫ßu ƒë√£ ƒë∆∞·ª£c load v√† g·ªôp, t·ªïng c·ªông c√≥ {len(ds_val_global)} m·∫´u.\")\n",
    "    \n",
    "    # (B√¢y gi·ªù b·∫°n c√≥ th·ªÉ d√πng 'ds_val_global' ƒë·ªÉ shuffle, save_to_disk, ho·∫∑c train)\n",
    "    # V√≠ d·ª•:\n",
    "    print(\"ƒêang tr·ªôn (shuffle)...\")\n",
    "    ds_val_global = ds_val_global.shuffle(seed=42)\n",
    "    print(\"ƒêang l∆∞u ra disk...\")\n",
    "    ds_val_global.save_to_disk(r\"D:\\HuggingFace_Cache\\cache\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI KHI ƒêANG T·∫¢I: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5094c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fee28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    \"\"\"T√≠nh Accuracy cho qu√° tr√¨nh ƒë√°nh gi√° (Evaluation).\"\"\"\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == p.label_ids).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195525bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechV2:\n",
    "    feature_extractor: Wav2Vec2FeatureExtractor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [feature[\"label\"] for feature in features]\n",
    "        batch = self.feature_extractor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch[\"labels\"] = torch.tensor(label_features, dtype=torch.long)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=======================================================\")\n",
    "print(\"üöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN H·ªñN H·ª¢P (MIXED TRAINING 100%)\")\n",
    "print(\"=======================================================\")\n",
    "SAVE_CHECKPOINT_DIR = r\"models\\Checkpoint\"\n",
    "SAVE_MODEL_DIR = r\"models\\saved\"\n",
    "try:\n",
    "    # --- 1. T·∫£i b·∫±ng Memory-Mapping (KH√îNG T·ªêN RAM) ---\n",
    "    print(f\"T·∫£i GLOBAL_train (77GB) t·ª´: {TRAIN_PATH}\")\n",
    "    ds_train = load_from_disk(TRAIN_PATH)\n",
    "    print(f\"T·∫£i GLOBAL_val t·ª´: {VAL_PATH}\")\n",
    "    ds_val = load_from_disk(VAL_PATH)\n",
    "    \n",
    "    print(f\"‚úÖ T·∫£i d·ªØ li·ªáu th√†nh c√¥ng (qua Memory-Map).\")\n",
    "    print(f\"   Train: {len(ds_train)} | Val: {len(ds_val)}\")\n",
    "\n",
    "    # --- 2. T·∫£i Model G·ªëc ---\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        num_labels=len(LANGUAGES)\n",
    "    )\n",
    "    \n",
    "    # --- 3. C·∫•u h√¨nh Arguments (S·ª≠ d·ª•ng batch 16 cho L40s) ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=SAVE_CHECKPOINT_DIR,\n",
    "        per_device_train_batch_size=16, # (Nh∆∞ b·∫°n n√≥i, s·∫Ω chi·∫øm ~42GB VRAM)\n",
    "        gradient_accumulation_steps=1, \n",
    "        dataloader_num_workers=2,       \n",
    "        eval_strategy=\"epoch\",         \n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=3,             # Train 3 epoch\n",
    "        learning_rate=5e-5, \n",
    "        fp16=True,                      # D√πng fp16 cho L40s/T4\n",
    "        save_total_limit=2,             \n",
    "        logging_steps=100,             \n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=True,    # T·ª± ƒë·ªông ch·ªçn model t·ªët nh·∫•t\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=ds_train, \n",
    "        eval_dataset=ds_val,   \n",
    "        tokenizer=feature_extractor,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # --- 4. Hu·∫•n luy·ªán ---\n",
    "    print(\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán...\")\n",
    "    trainer.train() \n",
    "    print(\"Hu·∫•n luy·ªán ho√†n t·∫•t.\")\n",
    "\n",
    "    # --- 5. L∆∞u Model Cu·ªëi c√πng ---\n",
    "    trainer.save_model(SAVE_MODEL_DIR) \n",
    "    feature_extractor.save_pretrained(SAVE_MODEL_DIR) \n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u model cu·ªëi c√πng (t·ªët nh·∫•t) t·∫°i: {SAVE_MODEL_DIR}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI TRONG QU√Å TR√åNH HU·∫§N LUY·ªÜN: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123046a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fced6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_TEST_PATH = r\"models\\Checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ae4eb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127724644b5641a6987b5026012b3276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeadff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. T·∫¢I MODEL V√Ä D·ªÆ LI·ªÜU ===\n",
    "\n",
    "print(f\"ƒêang t·∫£i model t·ª´: {MODEL_TO_TEST_PATH}\")\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(MODEL_TO_TEST_PATH)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_TO_TEST_PATH)\n",
    "\n",
    "print(f\"ƒêang t·∫£i d·ªØ li·ªáu validation t·ª´: {VAL_DATA_PATH}\")\n",
    "ds_val = load_from_disk(VAL_DATA_PATH)\n",
    "\n",
    "print(\"‚úÖ T·∫£i model v√† d·ªØ li·ªáu th√†nh c√¥ng.\")\n",
    "\n",
    "# === 3. CH·∫†Y ƒê√ÅNH GI√Å (PREDICT) ===\n",
    "\n",
    "# Kh·ªüi t·∫°o Data Collator\n",
    "data_collator = DataCollatorSpeechV2(feature_extractor=feature_extractor)\n",
    "\n",
    "# C·∫•u h√¨nh Trainer t·ªëi thi·ªÉu\n",
    "test_args = TrainingArguments(\n",
    "    output_dir=r\"output\", # Th∆∞ m·ª•c t·∫°m\n",
    "    per_device_eval_batch_size=16,          # TƒÉng batch size ƒë·ªÉ test nhanh\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o Trainer\n",
    "tester = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# --- CH·∫†Y D·ª∞ ƒêO√ÅN ---\n",
    "print(\"\\nB·∫Øt ƒë·∫ßu ch·∫°y d·ª± ƒëo√°n tr√™n t·∫≠p GLOBAL_val...\")\n",
    "results = tester.predict(ds_val) # S·ª≠ d·ª•ng ds_val ·ªü ƒë√¢y\n",
    "\n",
    "print(\"\\n--- K·∫æT QU·∫¢ ƒê√ÅNH GI√Å (TR√äN GLOBAL_val) ---\")\n",
    "# In ra c√°c ch·ªâ s·ªë (v√≠ d·ª•: test_loss, test_accuracy)\n",
    "# K·∫øt qu·∫£ s·∫Ω c√≥ d·∫°ng {'predict_loss': ..., 'predict_accuracy': ...}\n",
    "print(results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf76690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. T·∫¢I MODEL V√Ä D·ªÆ LI·ªÜU ===\n",
    "\n",
    "print(f\"ƒêang t·∫£i model t·ª´: {MODEL_TO_TEST_PATH}\")\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(MODEL_TO_TEST_PATH)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_TO_TEST_PATH)\n",
    "\n",
    "print(f\"ƒêang t·∫£i d·ªØ li·ªáu validation t·ª´: {TEST_DATA_PATH}\")\n",
    "ds_test = load_from_disk(TEST_DATA_PATH)\n",
    "\n",
    "print(\"‚úÖ T·∫£i model v√† d·ªØ li·ªáu th√†nh c√¥ng.\")\n",
    "\n",
    "# === 3. CH·∫†Y ƒê√ÅNH GI√Å (PREDICT) ===\n",
    "\n",
    "# Kh·ªüi t·∫°o Data Collator\n",
    "data_collator = DataCollatorSpeechV2(feature_extractor=feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# 1. C·∫§U H√åNH TH∆Ø M·ª§C L·ªñI\n",
    "# ====================================================\n",
    "# Th∆∞ m·ª•c ƒë·ªÉ l∆∞u c√°c file audio nh·∫≠n di·ªán sai\n",
    "ERROR_DIR = \"./error\"\n",
    "\n",
    "# X√≥a th∆∞ m·ª•c c≈© (n·∫øu c√≥) ƒë·ªÉ t·∫°o m·ªõi cho s·∫°ch\n",
    "if os.path.exists(ERROR_DIR):\n",
    "    shutil.rmtree(ERROR_DIR)\n",
    "os.makedirs(ERROR_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ C√°c file l·ªói s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o: {ERROR_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# 2. CH·∫†Y ƒê√ÅNH GI√Å (PREDICT)\n",
    "# ====================================================\n",
    "\n",
    "# C·∫•u h√¨nh Trainer t·ªëi thi·ªÉu (nh∆∞ c≈©)\n",
    "test_args = TrainingArguments(\n",
    "    output_dir=\"./temp_test\", \n",
    "    per_device_eval_batch_size=16,          \n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=2,       \n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "tester = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ B·∫Øt ƒë·∫ßu ch·∫°y d·ª± ƒëo√°n tr√™n t·∫≠p test...\")\n",
    "results = tester.predict(ds_test) \n",
    "\n",
    "# ====================================================\n",
    "# 3. PH√ÇN T√çCH V√Ä L∆ØU FILE L·ªñI\n",
    "# ====================================================\n",
    "print(\"\\nüîç ƒêang ph√¢n t√≠ch c√°c m·∫´u sai...\")\n",
    "\n",
    "# L·∫•y k·∫øt qu·∫£\n",
    "logits = results.predictions\n",
    "pred_ids = np.argmax(logits, axis=1) # Nh√£n d·ª± ƒëo√°n (0, 1, 2...)\n",
    "true_ids = results.label_ids         # Nh√£n th·∫≠t\n",
    "\n",
    "# Danh s√°ch ghi log\n",
    "error_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0610a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_OUTPUT_PATH = \"error/error_report.csv\"\n",
    "LANGUAGES = [\"vi\", \"en\", \"ja\", \"ko\", \"zh\", \"th\"]\n",
    "print(f\"T·ªïng s·ªë m·∫´u ki·ªÉm tra: {len(pred_ids)}\")\n",
    "\n",
    "for idx, (pred, true) in enumerate(zip(pred_ids, true_ids)):\n",
    "    if pred != true:\n",
    "        # === ƒê√ÇY L√Ä M·ªòT M·∫™U SAI ===\n",
    "        try:\n",
    "            # 1. L·∫•y t√™n ng√¥n ng·ªØ\n",
    "            true_lang = LANGUAGES[true]\n",
    "            pred_lang = LANGUAGES[pred]\n",
    "            \n",
    "            # 2. L·∫•y th√¥ng tin t·ª´ Dataset (File Arrow)\n",
    "            item = ds_test[idx]\n",
    "            \n",
    "            # 3. Tr√≠ch xu·∫•t ƒë∆∞·ªùng d·∫´n file g·ªëc (X·ª≠ l√Ω linh ho·∫°t)\n",
    "            audio_path = \"N/A\"\n",
    "            if 'audio' in item:\n",
    "                val = item['audio']\n",
    "                if isinstance(val, str):\n",
    "                    audio_path = val\n",
    "                elif isinstance(val, dict):\n",
    "                    # HuggingFace datasets th∆∞·ªùng l∆∞u audio d∆∞·ªõi d·∫°ng dict {'path': ..., 'array': ...}\n",
    "                    audio_path = val.get('path', 'Unknown Path')\n",
    "            \n",
    "            # 4. T√≠nh ƒë·ªô tin c·∫≠y (Confidence) c·ªßa d·ª± ƒëo√°n sai\n",
    "            # L·∫•y vector logit c·ªßa m·∫´u hi·ªán t·∫°i\n",
    "            sample_logits = logits[idx]\n",
    "            # D√πng Softmax ƒë·ªÉ chuy·ªÉn sang x√°c su·∫•t\n",
    "            probs = np.exp(sample_logits) / np.sum(np.exp(sample_logits))\n",
    "            confidence = probs[pred] # ƒê·ªô t·ª± tin v√†o c√°i sai\n",
    "            true_score = probs[true] # ƒê·ªô t·ª± tin v√†o c√°i ƒë√∫ng (th∆∞·ªùng s·∫Ω th·∫•p)\n",
    "\n",
    "            # 5. Ghi v√†o log\n",
    "            error_record = {\n",
    "                \"Index\": idx,\n",
    "                \"Audio_Path\": audio_path,  # ƒê∆∞·ªùng d·∫´n g·ªëc ƒë·ªÉ tra c·ª©u\n",
    "                \"True_Label\": true_lang,   # Nh√£n ƒë√∫ng\n",
    "                \"Pred_Label\": pred_lang,   # Nh√£n m√¥ h√¨nh ƒëo√°n sai\n",
    "                \"Confidence\": round(float(confidence), 4), # M·ª©c ƒë·ªô t·ª± tin khi sai\n",
    "                \"True_Label_Score\": round(float(true_score), 4) # ƒêi·ªÉm cho nh√£n ƒë√∫ng\n",
    "            }\n",
    "            \n",
    "            error_logs.append(error_record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è L·ªói tr√≠ch xu·∫•t t·∫°i d√≤ng {idx}: {e}\")\n",
    "\n",
    "# ====================================================\n",
    "# 4. T·ªîNG K·∫æT V√Ä XU·∫§T B√ÅO C√ÅO CSV\n",
    "# ====================================================\n",
    "print(f\"\\n‚úÖ ƒê√£ ho√†n t·∫•t ph√¢n t√≠ch! T√¨m th·∫•y {len(error_logs)} m·∫´u sai.\")\n",
    "\n",
    "if len(error_logs) > 0:\n",
    "    # T·∫°o DataFrame\n",
    "    df_errors = pd.DataFrame(error_logs)\n",
    "    \n",
    "    # S·∫Øp x·∫øp: ƒê∆∞a nh·ªØng l·ªói m√† m√¥ h√¨nh \"t·ª± tin nh·∫•t\" l√™n ƒë·∫ßu (Nguy hi·ªÉm nh·∫•t)\n",
    "    df_errors = df_errors.sort_values(by=\"Confidence\", ascending=False)\n",
    "    \n",
    "    # L∆∞u ra CSV\n",
    "    csv_path = os.path.join(ERROR_DIR, \"error_report.csv\")\n",
    "    df_errors.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"üìÑ B√°o c√°o chi ti·∫øt ƒë√£ l∆∞u t·∫°i: {csv_path}\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã 5 l·ªói ƒëi·ªÉn h√¨nh nh·∫•t\n",
    "    print(\"\\n--- 5 M·∫´u l·ªói c√≥ ƒë·ªô tin c·∫≠y cao nh·∫•t (Model sai nh∆∞ng r·∫•t t·ª± tin) ---\")\n",
    "    # Ch·ªçn c√°c c·ªôt quan tr·ªçng ƒë·ªÉ hi·ªÉn th·ªã\n",
    "    display_cols = ['Audio_Path', 'True_Label', 'Pred_Label', 'Confidence']\n",
    "    print(df_errors.head(5)[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"üéâ Ch√∫c m·ª´ng! M√¥ h√¨nh d·ª± ƒëo√°n ƒë√∫ng 100% tr√™n t·∫≠p n√†y (ho·∫∑c kh√¥ng t√¨m th·∫•y l·ªói).\")\n",
    "\n",
    "print(\"\\n--- K·∫æT QU·∫¢ METRICS T·ªîNG QU√ÅT ---\")\n",
    "print(results.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
